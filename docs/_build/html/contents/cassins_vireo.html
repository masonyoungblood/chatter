
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Cassin’s vireo &#8212; Chatter Documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=e7293a18" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=a1637f0b"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'contents/cassins_vireo';</script>
    <link rel="icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Humpback whales" href="humpback_whale.html" />
    <link rel="prev" title="Preparation" href="preparation.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Chatter Documentation - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Chatter Documentation - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Home
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Guide</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installing <code class="docutils literal notranslate"><span class="pre">chatter</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="flow_diagram.html">Flow diagram</a></li>
<li class="toctree-l1"><a class="reference internal" href="preparation.html">Preparation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Full Vignettes</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Cassin’s vireo</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Short Vignettes</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="humpback_whale.html">Humpback whales</a></li>
<li class="toctree-l1"><a class="reference internal" href="chimpanzee.html">Chimpanzees</a></li>
<li class="toctree-l1"><a class="reference internal" href="egyptian_fruit_bat.html">Egyptian fruit bats</a></li>
<li class="toctree-l1"><a class="reference internal" href="human.html">Humans</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../_autosummary/chatter.html">chatter</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../_autosummary/chatter.analyzer.html">chatter.analyzer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_autosummary/chatter.config.html">chatter.config</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_autosummary/chatter.data.html">chatter.data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_autosummary/chatter.features.html">chatter.features</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_autosummary/chatter.models.html">chatter.models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_autosummary/chatter.trainer.html">chatter.trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../_autosummary/chatter.utils.html">chatter.utils</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/masonyoungblood/chatter" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/contents/cassins_vireo.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Cassin’s vireo</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Setup">Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Preprocessing">Preprocessing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Segmentation">Segmentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Run-model">Run model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Postprocessing">Postprocessing</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="Cassin's-vireo">
<h1>Cassin’s vireo<a class="headerlink" href="#Cassin's-vireo" title="Link to this heading">#</a></h1>
<p>This notebook walks through a complete <code class="docutils literal notranslate"><span class="pre">chatter</span></code> workflow using recordings of Cassin’s vireo as a worked example. It is intended to be the main, end-to-end tutorial for the Python package, showing how each component fits together.</p>
<p>We will:</p>
<ul class="simple">
<li><p><strong>Configure</strong> <code class="docutils literal notranslate"><span class="pre">chatter</span></code> for this dataset (sampling, frequency range, segmentation options).</p></li>
<li><p><strong>Preprocess</strong> raw audio and extract clips that contain Cassin’s vireo songs and calls.</p></li>
<li><p><strong>Segment</strong> clips into individual acoustic units and save standardized spectrograms.</p></li>
<li><p><strong>Train</strong> a convolutional variational autoencoder (VAE) on those spectrograms.</p></li>
<li><p><strong>Extract features</strong> from the trained model.</p></li>
<li><p><strong>Post-process and visualize</strong> the learned latent space and a set of derived acoustic measures.</p></li>
</ul>
<p>If you are new to <code class="docutils literal notranslate"><span class="pre">chatter</span></code>, please read this notebook in its entirety and use it as a template for your own species or datasets.</p>
<p>The Cassin’s vireo recordings come from:</p>
<p>Hedley, R. W. (2016). Complexity, predictability, and time homogeneity of syntax in the songs of Cassin’s vireo (<em>Vireo cassinii</em>). <em>PLOS ONE</em>. <a class="reference external" href="https://www.doi.org/10.1371/journal.pone.0150822">https://www.doi.org/10.1371/journal.pone.0150822</a></p>
<p><img alt="cassins vireo" class="no-scaled-link" src="https://cdn.download.ams.birds.cornell.edu/api/v1/asset/465321811/1200" style="width: 50%;" /></p>
<p>© Michael Stubblefield (eBird S108126823)</p>
<section id="Setup">
<h2>Setup<a class="headerlink" href="#Setup" title="Link to this heading">#</a></h2>
<p>In this section we import <code class="docutils literal notranslate"><span class="pre">chatter</span></code> and a few standard scientific Python libraries, then define a configuration that controls every major step of the pipeline.</p>
<p>Key ideas:</p>
<ul class="simple">
<li><p><strong>Configuration dictionary</strong>: we start with a Python dict containing only the parameters we want to override (e.g., frequency range, preprocessing filters, segmentation thresholds). <code class="docutils literal notranslate"><span class="pre">chatter.make_config</span></code> fills in all remaining fields with sensible defaults.</p></li>
<li><p><strong>Analyzer</strong>: <code class="docutils literal notranslate"><span class="pre">chatter.Analyzer</span></code> orchestrates preprocessing, segmentation, and spectrogram creation. It is initialized with a config and the number of CPU cores to use (<code class="docutils literal notranslate"><span class="pre">n_jobs</span></code>).</p></li>
<li><p><strong>Trainer</strong>: <code class="docutils literal notranslate"><span class="pre">chatter.Trainer</span></code> wraps the autoencoder model and training loop.</p></li>
<li><p><strong>Paths</strong>: we keep all file system paths in clearly named variables (<code class="docutils literal notranslate"><span class="pre">raw_dir</span></code>, <code class="docutils literal notranslate"><span class="pre">input_dir</span></code>, <code class="docutils literal notranslate"><span class="pre">processed_dir</span></code>, <code class="docutils literal notranslate"><span class="pre">h5_path</span></code>, <code class="docutils literal notranslate"><span class="pre">csv_path</span></code>, <code class="docutils literal notranslate"><span class="pre">model_dir</span></code>, <code class="docutils literal notranslate"><span class="pre">output_csv_path</span></code>) so you can easily adapt this notebook to your own directory structure.</p></li>
</ul>
<p>When adapting this example, you will typically:</p>
<ol class="arabic simple">
<li><p>Adjust the config values to fit your species or recording conditions.</p></li>
<li><p>Change the path variables to point to your own data locations.</p></li>
<li><p>Optionally change <code class="docutils literal notranslate"><span class="pre">n_jobs</span></code> based on how many CPU cores and how much RAM you have available.</p></li>
</ol>
<p>First we import Chatter and a few core scientific Python libraries. These imports are all you need to follow along with this notebook and run the full pipeline on your own data.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import packages</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">chatter</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
</pre></div>
</div>
</div>
<p>This next cell defines our analysis configuration and initializes the main Chatter objects. We override a few defaults (e.g., frequency range and segmentation settings), call <code class="docutils literal notranslate"><span class="pre">make_config()</span></code> to fill in the rest, construct an <code class="docutils literal notranslate"><span class="pre">Analyzer</span></code> and <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>, and then specify all the key paths on disk for this example dataset.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># set config parameters that depart from defaults</span>
<span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="c1"># spectrogram parameters</span>
    <span class="s2">&quot;fmin&quot;</span><span class="p">:</span> <span class="mi">1500</span><span class="p">,</span>
    <span class="s2">&quot;fmax&quot;</span><span class="p">:</span> <span class="mi">7500</span><span class="p">,</span>
    <span class="c1"># preprocessing parameters</span>
    <span class="s2">&quot;use_biodenoising&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="s2">&quot;use_noisereduce&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="s2">&quot;high_pass&quot;</span><span class="p">:</span> <span class="mi">1500</span><span class="p">,</span>
    <span class="s2">&quot;low_pass&quot;</span><span class="p">:</span> <span class="mi">7500</span><span class="p">,</span>
    <span class="s2">&quot;static&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="s2">&quot;threshold&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="c1"># simple segmentation parameters</span>
    <span class="s2">&quot;simple_noise_floor&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">60</span><span class="p">,</span>
    <span class="s2">&quot;simple_silence_threshold_db&quot;</span><span class="p">:</span> <span class="o">-</span><span class="mi">50</span><span class="p">,</span>
    <span class="s2">&quot;simple_min_silence_length&quot;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span>
    <span class="s2">&quot;simple_max_unit_length&quot;</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">,</span>
    <span class="s2">&quot;simple_min_unit_length&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
    <span class="c1"># other parameters</span>
    <span class="s2">&quot;plot_clip_duration&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">chatter</span><span class="o">.</span><span class="n">make_config</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

<span class="c1"># initialize the analyzer with the configuration</span>
<span class="c1"># using only 8 cores to avoid memory crash during segmentation</span>
<span class="n">analyzer</span> <span class="o">=</span> <span class="n">chatter</span><span class="o">.</span><span class="n">Analyzer</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">chatter</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

<span class="c1"># set paths</span>
<span class="n">raw_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;/Volumes/Expansion/data/chatter/examples/cassins_vireo/recordings/raw&quot;</span><span class="p">)</span>
<span class="n">input_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span>
    <span class="s2">&quot;/Volumes/Expansion/data/chatter/examples/cassins_vireo/recordings/clips&quot;</span>
<span class="p">)</span>
<span class="n">processed_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span>
    <span class="s2">&quot;/Volumes/Expansion/data/chatter/examples/cassins_vireo/recordings/processed&quot;</span>
<span class="p">)</span>
<span class="n">h5_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;/Volumes/Expansion/data/chatter/examples/cassins_vireo/spectrograms.h5&quot;</span><span class="p">)</span>
<span class="n">csv_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span>
    <span class="s2">&quot;/Volumes/Expansion/data/chatter/examples/cassins_vireo/spectrograms.csv&quot;</span>
<span class="p">)</span>
<span class="n">model_dir</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&quot;/Volumes/Expansion/data/chatter/examples/cassins_vireo/model&quot;</span><span class="p">)</span>
<span class="n">output_csv_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span>
    <span class="s2">&quot;/Volumes/Expansion/data/chatter/examples/cassins_vireo/output.csv&quot;</span>
<span class="p">)</span>
<span class="n">output_html_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span>
    <span class="s2">&quot;/Volumes/Expansion/data/chatter/examples/cassins_vireo/cassins_vireo_embedding.html&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Using 8 cores for parallel processing
Initializing convolutional variational autoencoder
Using device: mps
</pre></div></div>
</div>
</section>
<section id="Preprocessing">
<h2>Preprocessing<a class="headerlink" href="#Preprocessing" title="Link to this heading">#</a></h2>
<p>Raw field recordings are typically long, noisy, and contain many species. In <code class="docutils literal notranslate"><span class="pre">chatter</span></code> we break the problem into two or three stages before segmentation:</p>
<ol class="arabic simple">
<li><p><strong>Species-specific clip extraction</strong> (<code class="docutils literal notranslate"><span class="pre">extract_species_clips</span></code>) (optional):</p>
<ul class="simple">
<li><p>We scan the raw directory with BirdNET and keep only the time intervals where Cassin’s Vireo is detected above a chosen confidence threshold.</p></li>
<li><p>Each detection is exported as a short WAV file into <code class="docutils literal notranslate"><span class="pre">input_dir</span></code>, preserving a directory structure that mirrors the original recordings.</p></li>
</ul>
</li>
<li><p><strong>Preprocessing demo</strong> (<code class="docutils literal notranslate"><span class="pre">demo_preprocessing</span></code>):</p>
<ul class="simple">
<li><p>Before batch-processing everything, we take one random clip and run it through the full preprocessing pipeline in memory.</p></li>
<li><p>This produces a diagnostic plot so you can visually confirm that filters, denoising, and normalization look reasonable for your data.</p></li>
</ul>
</li>
<li><p><strong>Batch preprocessing</strong> (<code class="docutils literal notranslate"><span class="pre">preprocess_directory</span></code>):</p>
<ul class="simple">
<li><p>We then apply the same preprocessing operations to every clip in <code class="docutils literal notranslate"><span class="pre">input_dir</span></code> and save standardized WAV files (same sample rate, channels, and loudness) into <code class="docutils literal notranslate"><span class="pre">processed_dir</span></code>.</p></li>
</ul>
</li>
</ol>
<p>For your own data, you can skip step 1 if you already have species-specific clips, but it is often useful when starting from long, mixed-species recordings.</p>
<p>We start by extracting clips that actually contain Cassin’s vireo. <code class="docutils literal notranslate"><span class="pre">extract_species_clips()</span></code> scans long raw recordings in <code class="docutils literal notranslate"><span class="pre">raw_dir</span></code> with BirdNET, identifies segments where the target species is present above the specified confidence threshold, and writes those segments as shorter WAV files into <code class="docutils literal notranslate"><span class="pre">input_dir</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># identify and export clips with cassin&#39;s vireo</span>
<span class="n">analyzer</span><span class="o">.</span><span class="n">extract_species_clips</span><span class="p">(</span>
    <span class="n">input_dir</span><span class="o">=</span><span class="n">raw_dir</span><span class="p">,</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="n">input_dir</span><span class="p">,</span>
    <span class="n">species</span><span class="o">=</span><span class="s2">&quot;Cassin&#39;s Vireo&quot;</span><span class="p">,</span>
    <span class="n">confidence_threshold</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--- Found 221 audio files to process ---
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Detecting &#39;Cassin&#39;s Vireo&#39;: 100%|██████████| 221/221 [09:51&lt;00:00,  2.67s/it]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

--- Species clip extraction complete. Clips saved to /Volumes/Expansion/data/chatter/examples/cassins_vireo/recordings/clips ---
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<p>Before launching full preprocessing, we run a quick visual check. <code class="docutils literal notranslate"><span class="pre">demo_preprocessing()</span></code> selects a single clip, applies the same preprocessing steps that will be used in batch mode, and plots the original vs. processed spectrogram so you can confirm that the transformations look sensible.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># demo the preprocessing pipeline</span>
<span class="n">analyzer</span><span class="o">.</span><span class="n">demo_preprocessing</span><span class="p">(</span><span class="n">input_dir</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--- Demoing preprocessing for: 1265_Cassin&#39;s_Vireo_7_230.00s-238.00s.wav ---
   Segment: 2.89s - 7.89s
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/contents_cassins_vireo_11_1.png" src="../_images/contents_cassins_vireo_11_1.png" />
</div>
</div>
<p>Once we are happy with the preprocessing settings, we apply them to every clip. <code class="docutils literal notranslate"><span class="pre">preprocess_directory()</span></code> walks over all files in <code class="docutils literal notranslate"><span class="pre">input_dir</span></code>, runs the full preprocessing pipeline, and writes standardized WAV files into <code class="docutils literal notranslate"><span class="pre">processed_dir</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># preprocess recordings</span>
<span class="n">analyzer</span><span class="o">.</span><span class="n">preprocess_directory</span><span class="p">(</span><span class="n">input_dir</span><span class="o">=</span><span class="n">input_dir</span><span class="p">,</span> <span class="n">processed_dir</span><span class="o">=</span><span class="n">processed_dir</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--- Found 714 audio files to preprocess ---
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Preprocessing audio: 100%|██████████| 714/714 [00:51&lt;00:00, 13.86it/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

--- Preprocessing complete. Standardized WAV audio saved to /Volumes/Expansion/data/chatter/examples/cassins_vireo/recordings/processed ---
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
</section>
<section id="Segmentation">
<h2>Segmentation<a class="headerlink" href="#Segmentation" title="Link to this heading">#</a></h2>
<p>Once clips have been cleaned and standardized, we segment each file into shorter <strong>acoustic units</strong> (syllables or notes). Chatter supports two segmentation strategies, both exposed through the <code class="docutils literal notranslate"><span class="pre">Analyzer</span></code>:</p>
<ul class="simple">
<li><p><strong>Simple, amplitude-based segmentation</strong> (<code class="docutils literal notranslate"><span class="pre">simple=True</span></code>): operates directly on the waveform using an RMS energy threshold and minimum/maximum duration constraints.</p></li>
<li><p><strong>Pykanto-inspired, image-based segmentation</strong> (<code class="docutils literal notranslate"><span class="pre">simple=False</span></code>): operates on mel spectrogram images using the <code class="docutils literal notranslate"><span class="pre">pykanto</span></code> unit-finding algorithm.</p></li>
</ul>
<p>In this notebook we:</p>
<ol class="arabic simple">
<li><p>Use <code class="docutils literal notranslate"><span class="pre">demo_segmentation</span></code> to visualize how the current segmentation settings behave on a few random clips. This is where you should tune thresholds, noise floors, and min/max unit lengths for your species.</p></li>
<li><p>Call <code class="docutils literal notranslate"><span class="pre">segment_and_create_spectrograms</span></code> to:</p>
<ul class="simple">
<li><p>Run segmentation on all preprocessed WAV files in <code class="docutils literal notranslate"><span class="pre">processed_dir</span></code>.</p></li>
<li><p>Slice each file’s spectrogram into fixed-size unit spectrograms.</p></li>
<li><p>Save the spectrograms to an HDF5 file (<code class="docutils literal notranslate"><span class="pre">h5_path</span></code>) and unit-level metadata (file name, onset, offset, etc.) to a CSV (<code class="docutils literal notranslate"><span class="pre">csv_path</span></code>).</p></li>
</ul>
</li>
</ol>
<p>The resulting <code class="docutils literal notranslate"><span class="pre">unit_df</span></code> DataFrame is the canonical representation of your segmented dataset and will be used in the modeling and postprocessing steps that follow.</p>
<p>Before committing to a full segmentation run, we visually inspect a few random clips. Each call to <code class="docutils literal notranslate"><span class="pre">demo_segmentation()</span></code> selects a file from <code class="docutils literal notranslate"><span class="pre">processed_dir</span></code>, runs the chosen segmentation method, and plots the spectrogram with detected unit boundaries overlaid.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># preview the segmentation pipeline</span>
<span class="n">analyzer</span><span class="o">.</span><span class="n">demo_segmentation</span><span class="p">(</span><span class="n">input_dir</span><span class="o">=</span><span class="n">processed_dir</span><span class="p">,</span> <span class="n">simple</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">analyzer</span><span class="o">.</span><span class="n">demo_segmentation</span><span class="p">(</span><span class="n">input_dir</span><span class="o">=</span><span class="n">processed_dir</span><span class="p">,</span> <span class="n">simple</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">analyzer</span><span class="o">.</span><span class="n">demo_segmentation</span><span class="p">(</span><span class="n">input_dir</span><span class="o">=</span><span class="n">processed_dir</span><span class="p">,</span> <span class="n">simple</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">analyzer</span><span class="o">.</span><span class="n">demo_segmentation</span><span class="p">(</span><span class="n">input_dir</span><span class="o">=</span><span class="n">processed_dir</span><span class="p">,</span> <span class="n">simple</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--- Demoing segmentation for: 1540_Cassin&#39;s_Vireo_1_2474.00s-2479.00s.wav ---
   Segment: 0.00s - 5.00s
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/contents_cassins_vireo_16_1.png" src="../_images/contents_cassins_vireo_16_1.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--- Demoing segmentation for: 1161_Cassin&#39;s_Vireo_52_2327.00s-2335.00s.wav ---
   Segment: 1.66s - 6.66s
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/contents_cassins_vireo_16_3.png" src="../_images/contents_cassins_vireo_16_3.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--- Demoing segmentation for: 1260_Cassin&#39;s_Vireo_2_2078.00s-2083.00s.wav ---
   Segment: 0.00s - 5.00s
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/contents_cassins_vireo_16_5.png" src="../_images/contents_cassins_vireo_16_5.png" />
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--- Demoing segmentation for: 1606_Cassin&#39;s_Vireo_2_620.00s-625.00s.wav ---
   Segment: 0.00s - 5.00s
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/contents_cassins_vireo_16_7.png" src="../_images/contents_cassins_vireo_16_7.png" />
</div>
</div>
<p>After we are satisfied with the segmentation behavior, we apply it to the full dataset. <code class="docutils literal notranslate"><span class="pre">segment_and_create_spectrograms()</span></code> runs segmentation on every file in <code class="docutils literal notranslate"><span class="pre">processed_dir</span></code>, slices the corresponding spectrograms into fixed-size units, writes them to <code class="docutils literal notranslate"><span class="pre">h5_path</span></code>, and builds the <code class="docutils literal notranslate"><span class="pre">unit_df</span></code> metadata table used by the model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># segment units and save spectrograms</span>
<span class="n">unit_df</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">segment_and_create_spectrograms</span><span class="p">(</span>
    <span class="n">processed_dir</span><span class="o">=</span><span class="n">processed_dir</span><span class="p">,</span> <span class="n">h5_path</span><span class="o">=</span><span class="n">h5_path</span><span class="p">,</span> <span class="n">csv_path</span><span class="o">=</span><span class="n">csv_path</span><span class="p">,</span> <span class="n">simple</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

--- Found 714 files to segment using simple (amplitude-based) method ---
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Segmenting and saving spectrograms: 100%|██████████| 714/714 [00:08&lt;00:00, 84.37it/s]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

--- Data preparation complete. Created records for 2692 units ---
Spectrograms saved to /Volumes/Expansion/data/chatter/examples/cassins_vireo/spectrograms.h5
Unit metadata saved to /Volumes/Expansion/data/chatter/examples/cassins_vireo/spectrograms.csv
</pre></div></div>
</div>
</section>
<section id="Run-model">
<h2>Run model<a class="headerlink" href="#Run-model" title="Link to this heading">#</a></h2>
<p>With segmented unit spectrograms in hand, we fit a <strong>convolutional variational autoencoder (VAE)</strong> that learns a low-dimensional representation (latent space) of Cassin’s vireo syllables.</p>
<p>The modeling workflow here has four main steps:</p>
<ol class="arabic simple">
<li><p><strong>Train the autoencoder</strong> (<code class="docutils literal notranslate"><span class="pre">train_ae</span></code>):</p>
<ul class="simple">
<li><p>Uses <code class="docutils literal notranslate"><span class="pre">unit_df</span></code> and <code class="docutils literal notranslate"><span class="pre">h5_path</span></code> to draw batches of unit spectrograms.</p></li>
<li><p>Optimizes a reconstruction + KL-divergence loss over multiple epochs.</p></li>
<li><p>Saves the best-performing model parameters and a loss history CSV to <code class="docutils literal notranslate"><span class="pre">model_dir</span></code>.</p></li>
</ul>
</li>
<li><p><strong>Reload the trained model</strong> (<code class="docutils literal notranslate"><span class="pre">Trainer.from_trained</span></code>):</p>
<ul class="simple">
<li><p>Demonstrates how to restore a model from disk using just the config and <code class="docutils literal notranslate"><span class="pre">model_dir</span></code>.</p></li>
<li><p>This is the entry point you would typically use in downstream analysis notebooks.</p></li>
</ul>
</li>
<li><p><strong>Inspect reconstructions</strong> (<code class="docutils literal notranslate"><span class="pre">plot_reconstructions</span></code>):</p>
<ul class="simple">
<li><p>Plots original vs. reconstructed spectrograms for a subset of units.</p></li>
<li><p>Helps you visually assess whether the model is capturing relevant structure without overfitting.</p></li>
</ul>
</li>
<li><p><strong>Extract latent features</strong> (<code class="docutils literal notranslate"><span class="pre">extract_and_save_features</span></code>):</p>
<ul class="simple">
<li><p>Runs all units through the encoder to obtain latent vectors and related diagnostics.</p></li>
<li><p>Writes a new CSV (<code class="docutils literal notranslate"><span class="pre">output_csv_path</span></code>) that augments <code class="docutils literal notranslate"><span class="pre">unit_df</span></code> with these model-derived features.</p></li>
</ul>
</li>
</ol>
<p>The remainder of the notebook shows how to work with this feature table to produce visualizations and summary statistics.</p>
<p>We now train the autoencoder on all segmented units. <code class="docutils literal notranslate"><span class="pre">train_ae()</span></code> reads batches of spectrograms from <code class="docutils literal notranslate"><span class="pre">h5_path</span></code> using the indices in <code class="docutils literal notranslate"><span class="pre">unit_df</span></code>, optimizes the VAE for a fixed number of epochs, and saves the trained model and loss history to <code class="docutils literal notranslate"><span class="pre">model_dir</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># train ae</span>
<span class="n">model</span><span class="o">.</span><span class="n">train_ae</span><span class="p">(</span><span class="n">unit_df</span><span class="o">=</span><span class="n">unit_df</span><span class="p">,</span> <span class="n">h5_path</span><span class="o">=</span><span class="n">h5_path</span><span class="p">,</span> <span class="n">model_dir</span><span class="o">=</span><span class="n">model_dir</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--- Training on the full dataset of 2692 units ---

Starting training for 100 epochs using 4 DataLoader workers...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Training model: 100%|██████████| 100/100 [09:39&lt;00:00,  5.79s/it, loss=1171.2967]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--- Training complete. Model saved to /Volumes/Expansion/data/chatter/examples/cassins_vireo/model/model.pth ---
Loss history saved to /Volumes/Expansion/data/chatter/examples/cassins_vireo/model/loss.csv
</pre></div></div>
</div>
<p>This cell shows how to reload a previously trained model. <code class="docutils literal notranslate"><span class="pre">Trainer.from_trained()</span></code> reconstructs the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> with weights and optimizer state from <code class="docutils literal notranslate"><span class="pre">model_dir</span></code>, which is the typical starting point for analysis notebooks that consume a trained model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># load trained vae</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">chatter</span><span class="o">.</span><span class="n">Trainer</span><span class="o">.</span><span class="n">from_trained</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">model_dir</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Instantiating Trainer from pre-trained model at /Volumes/Expansion/data/chatter/examples/cassins_vireo/model...
Initializing convolutional variational autoencoder
Using device: mps
Successfully loaded pre-trained model from /Volumes/Expansion/data/chatter/examples/cassins_vireo/model/model.pth
</pre></div></div>
</div>
<p>Before trusting the model for feature extraction, we visually inspect its reconstructions. <code class="docutils literal notranslate"><span class="pre">plot_reconstructions()</span></code> shows side-by-side original and reconstructed spectrograms for a sample of units so you can check that key structure is being captured.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># assess the quality of reconstruction</span>
<span class="n">model</span><span class="o">.</span><span class="n">plot_reconstructions</span><span class="p">(</span><span class="n">unit_df</span><span class="o">=</span><span class="n">unit_df</span><span class="p">,</span> <span class="n">h5_path</span><span class="o">=</span><span class="n">h5_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/contents_cassins_vireo_25_0.png" src="../_images/contents_cassins_vireo_25_0.png" />
</div>
</div>
<p>Finally, we extract latent features for every unit and save them to disk. <code class="docutils literal notranslate"><span class="pre">extract_and_save_features()</span></code> runs the encoder on all spectrograms, attaches the resulting vectors and diagnostics to <code class="docutils literal notranslate"><span class="pre">unit_df</span></code>, and writes an augmented CSV to <code class="docutils literal notranslate"><span class="pre">output_csv_path</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># export the latent features</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">extract_and_save_features</span><span class="p">(</span>
    <span class="n">unit_df</span><span class="o">=</span><span class="n">unit_df</span><span class="p">,</span>
    <span class="n">h5_path</span><span class="o">=</span><span class="n">h5_path</span><span class="p">,</span>
    <span class="n">model_dir</span><span class="o">=</span><span class="n">model_dir</span><span class="p">,</span>
    <span class="n">output_csv_path</span><span class="o">=</span><span class="n">output_csv_path</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

--- Starting feature extraction ---
Successfully loaded pre-trained model from /Volumes/Expansion/data/chatter/examples/cassins_vireo/model/model.pth
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Extracting features: 100%|██████████| 43/43 [00:06&lt;00:00,  6.68it/s]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

--- Pipeline complete. Exported data for 2692 units to /Volumes/Expansion/data/chatter/examples/cassins_vireo/output.csv ---
</pre></div></div>
</div>
</section>
<section id="Postprocessing">
<h2>Postprocessing<a class="headerlink" href="#Postprocessing" title="Link to this heading">#</a></h2>
<p>At this point we have a table where each row is a segmented unit and columns include:</p>
<ul class="simple">
<li><p><strong>Basic metadata</strong> (original file, onset, offset).</p></li>
<li><p><strong>Latent features</strong> from the trained VAE.</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">FeatureProcessor</span></code> class provides a convenient interface for turning these features into visualizations and higher-level acoustic measures:</p>
<ol class="arabic simple">
<li><p><strong>Load features into a processor</strong> (<code class="docutils literal notranslate"><span class="pre">FeatureProcessor</span></code>): wraps the DataFrame and config.</p></li>
<li><p><strong>Dimensionality reduction and visualization</strong>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">run_pacmap()</span></code> computes a 2D embedding of the latent space using PaCMAP, a more robust extension of UMAP.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">static_embedding_plot()</span></code> creates a publication-ready figure with points in latent space and overlaid spectrogram cutouts for representative units.</p></li>
</ul>
</li>
<li><p><strong>Sequence-level structure</strong>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">assign_sequence_ids()</span></code> groups units into sequences based on temporal proximity (here using a 1-second gap threshold between units).</p></li>
</ul>
</li>
<li><p><strong>Standard acoustic measures</strong>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">compute_frequency_statistics()</span></code> calculates summary statistics (e.g., frequency quantiles) that are commonly used in birdsong research.</p></li>
</ul>
</li>
<li><p><strong>Neighborhood and transition statistics</strong>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">compute_density_probability()</span></code> estimates how densely populated each point is in latent space, by fitting a masked autoregressive flow with the <code class="docutils literal notranslate"><span class="pre">denmarf</span></code> package.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">compute_cosine_distances()</span></code> measures the path length between subsequent units within a sequence, using the cosine distance.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">compute_sse_resid()</span></code> fits a simple vector autoregression (VAR) model to sequences and uses residuals as a measure of transition likelihood.</p></li>
</ul>
</li>
<li><p><strong>Export results</strong>:</p>
<ul class="simple">
<li><p>Finally, we write the enriched DataFrame back to <code class="docutils literal notranslate"><span class="pre">output_csv_path</span></code>, creating a single CSV that contains unit-level metadata, model-derived features, and a rich set of postprocessed measures.</p></li>
</ul>
</li>
</ol>
<p>You can treat this final CSV as the main output of the Chatter pipeline for downstream statistical analysis, visualization, or integration with behavioral and ecological data. Note that the reduced dimensions from PaCMAP are used <em>only</em> for visualization, and all other analyses are run on the original embeddings from the VAE.</p>
<p>We now wrap the feature CSV in a <code class="docutils literal notranslate"><span class="pre">FeatureProcessor</span></code>. This helper class keeps the DataFrame and config together and exposes convenience methods for dimensionality reduction, plotting, and calculating additional acoustic statistics.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># load in latent features</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">chatter</span><span class="o">.</span><span class="n">FeatureProcessor</span><span class="p">(</span><span class="n">analyzer</span><span class="o">.</span><span class="n">load_df</span><span class="p">(</span><span class="n">output_csv_path</span><span class="p">),</span> <span class="n">config</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Attempting to load /Volumes/Expansion/data/chatter/examples/cassins_vireo/output.csv...
--- Successfully loaded /Volumes/Expansion/data/chatter/examples/cassins_vireo/output.csv ---
</pre></div></div>
</div>
<p>To make the high-dimensional latent features easier to explore, we first compute a 2D embedding. <code class="docutils literal notranslate"><span class="pre">run_pacmap()</span></code> applies the PaCMAP algorithm to the latent vectors and stores the resulting coordinates in the feature table.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># run pacmap to get two-dimensional embedding for visualization</span>
<span class="n">output</span><span class="o">.</span><span class="n">run_pacmap</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--- Running PaCMAP dimensionality reduction ---
--- PaCMAP complete ---
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;chatter.features.FeatureProcessor at 0x341957cb0&gt;
</pre></div></div>
</div>
<p>Now we create a 2D visualization of the latent space. <code class="docutils literal notranslate"><span class="pre">static_embedding_plot()</span></code> uses the PaCMAP coordinates to produce a publication-ready figure with unit points, density shading, and overlaid spectrogram callouts for informative examples. By playing around with the seed we can modify which points are shown.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create static plot</span>
<span class="n">output</span><span class="o">.</span><span class="n">static_embedding_plot</span><span class="p">(</span>
    <span class="n">h5_path</span><span class="o">=</span><span class="n">h5_path</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span>
    <span class="n">focal_quantile</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">point_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">point_alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">margin</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
    <span class="n">zoom_padding</span><span class="o">=</span><span class="mf">0.42</span><span class="p">,</span>
    <span class="n">num_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--- Automatically selecting focal points from quadrants with seed 11 ---
--- Finding nearest neighbors ---
--- Creating the plot ---
--- Plotting density background (using fast 2d histogram) ---
--- Calculating callout positions and adding spectrograms ---
--- Displaying plot ---
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/contents_cassins_vireo_34_1.png" src="../_images/contents_cassins_vireo_34_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;chatter.features.FeatureProcessor at 0x341957cb0&gt;
</pre></div></div>
</div>
<p>We can also create an interactive version of this. The actual output of <code class="docutils literal notranslate"><span class="pre">export_interactive_embedding()</span></code> is an HTML file, but the example below is a screen capture of it.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create interactive plot</span>
<span class="n">output</span><span class="o">.</span><span class="n">interactive_embedding_plot</span><span class="p">(</span>
    <span class="n">h5_path</span><span class="o">=</span><span class="n">h5_path</span><span class="p">,</span> <span class="n">output_html_path</span><span class="o">=</span><span class="n">output_html_path</span><span class="p">,</span> <span class="n">point_alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">point_size</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--- Encoding spectrogram thumbnails for HTML export ---
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Thumbnails: 100%|██████████| 2692/2692 [00:02&lt;00:00, 1332.59it/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--- Interactive HTML embedding saved to /Volumes/Expansion/data/chatter/examples/cassins_vireo/cassins_vireo_embedding.html ---
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;chatter.features.FeatureProcessor at 0x385467cb0&gt;
</pre></div></div>
</div>
<p><img alt="cassins vireo embedding" class="no-scaled-link" src="../_images/cassins_vireo_embedding.gif" style="width: 100%;" /></p>
<p>After visualizing the embedding, we group units into temporal sequences. <code class="docutils literal notranslate"><span class="pre">assign_sequence_ids()</span></code> walks through units ordered by time and starts a new <code class="docutils literal notranslate"><span class="pre">seq_id</span></code> whenever the gap between adjacent units exceeds the specified cutoff (here 1 second).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># assign sequence ids based on the 1-second cutoff</span>
<span class="n">output</span><span class="o">.</span><span class="n">assign_sequence_ids</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--- Assigning seq_id using seq_bound = 1.0 seconds ---
--- seq_id assignment complete; total sequences: 1690 ---
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;chatter.features.FeatureProcessor at 0x341957cb0&gt;
</pre></div></div>
</div>
<p>Here we use <code class="docutils literal notranslate"><span class="pre">compute_frequency_statistics()</span></code> to compute standard acoustic measures familiar from birdsong research: minimum, mean, and maximum frequency.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># calculate standard acoustic measures used in birdsong research</span>
<span class="n">output</span><span class="o">.</span><span class="n">compute_frequency_statistics</span><span class="p">(</span><span class="n">h5_path</span><span class="o">=</span><span class="n">h5_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--- Computing frequency statistics from spectrograms ---
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Analyzing spectrograms: 100%|██████████| 2692/2692 [00:01&lt;00:00, 1483.02it/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--- Frequency statistics computation complete ---
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;chatter.features.FeatureProcessor at 0x341957cb0&gt;
</pre></div></div>
</div>
<p>We also estimate how densely populated each point is in the latent space. <code class="docutils literal notranslate"><span class="pre">compute_density_probability()</span></code> assigns a density-based score to each unit, which can be useful for identifying rare or typical syllables.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># compute density probability of each unit</span>
<span class="n">output</span><span class="o">.</span><span class="n">compute_density_probability</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--- Computing density probability estimates using denmarf ---
    Using 32-dimensional latent feature space.
    Fitting MAF model on 2692 samples (device: mps)...
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
current average log likelihood: nan: 100%|██████████| 1000/1000 [07:31&lt;00:00,  2.21it/s]
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
best average log likelihood: -41.249
    Scoring samples...
--- Density estimation complete. Added &#39;density_log_prob&#39; to DataFrame ---
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;chatter.features.FeatureProcessor at 0x341957cb0&gt;
</pre></div></div>
</div>
<p>Next we quantify the path length between subsequent units in sequences. <code class="docutils literal notranslate"><span class="pre">compute_cosine_distances()</span></code> computes cosine distances between successive latent vectors, which can be interpreted as a measure of acoustic change rate over time.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># compute cosine distances between subsequent units in sequences</span>
<span class="n">output</span><span class="o">.</span><span class="n">compute_cosine_distances</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--- Computing cosine distances between subsequent syllables (within seq_id) ---
--- Cosine distance calculation complete (within seq_id only) ---
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;chatter.features.FeatureProcessor at 0x341957cb0&gt;
</pre></div></div>
</div>
<p>Here we estimate how surprising each unit-to-unit transition is. <code class="docutils literal notranslate"><span class="pre">compute_sse_resid()</span></code> fits a simple vector autoregression (VAR) model to sequences in latent space and uses the summed squared residuals as a measure of transition likelihood (larger values indicate less expected transitions given recent context).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># compute the likelihood of each transition between units</span>
<span class="n">output</span><span class="o">.</span><span class="n">compute_sse_resid</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--- Running global VAR model (OLS) with lag size p = 3 ---
--- Global VAR model (OLS) complete; sse_resid computed for all sequences ---
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;chatter.features.FeatureProcessor at 0x341957cb0&gt;
</pre></div></div>
</div>
<p>Before finishing, we save the enriched feature table back to disk. This CSV combines unit-level metadata, VAE-derived features, sequence IDs, and all postprocessed measures so it can be used in downstream analyses or other software. Note that the first unit of each sequence is given NaN for <code class="docutils literal notranslate"><span class="pre">cosine_dist</span></code> and <code class="docutils literal notranslate"><span class="pre">sse_resid</span></code>, since those values are relative to the first unit in each sequence.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># preview the final data frame</span>
<span class="n">output</span><span class="o">.</span><span class="n">df</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>source_file</th>
      <th>unit_index</th>
      <th>onset</th>
      <th>offset</th>
      <th>max_unit_length_s</th>
      <th>h5_index</th>
      <th>ae_feat_0</th>
      <th>ae_feat_1</th>
      <th>ae_feat_2</th>
      <th>ae_feat_3</th>
      <th>...</th>
      <th>pacmap_x</th>
      <th>pacmap_y</th>
      <th>seq_id</th>
      <th>min_freq</th>
      <th>mean_freq</th>
      <th>max_freq</th>
      <th>time_bin_ms</th>
      <th>density_log_prob</th>
      <th>cosine_dist</th>
      <th>sse_resid</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>hedley_2016/Wav Files 1/1113_Cassin's_Vireo_1_...</td>
      <td>0</td>
      <td>0.031927</td>
      <td>0.374422</td>
      <td>0.8</td>
      <td>1971</td>
      <td>1.410389</td>
      <td>-2.699534</td>
      <td>1.295568</td>
      <td>0.646331</td>
      <td>...</td>
      <td>8.095862</td>
      <td>-2.044903</td>
      <td>1</td>
      <td>1500.000000</td>
      <td>2375.142101</td>
      <td>7129.297213</td>
      <td>6.25</td>
      <td>-42.518436</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>hedley_2016/Wav Files 1/1113_Cassin's_Vireo_1_...</td>
      <td>1</td>
      <td>0.641451</td>
      <td>0.873651</td>
      <td>0.8</td>
      <td>1972</td>
      <td>-0.976862</td>
      <td>0.353828</td>
      <td>-1.931226</td>
      <td>1.852069</td>
      <td>...</td>
      <td>6.673967</td>
      <td>-2.631289</td>
      <td>1</td>
      <td>2138.929378</td>
      <td>2505.763628</td>
      <td>2936.216478</td>
      <td>6.25</td>
      <td>-26.115707</td>
      <td>1.052800</td>
      <td>62.332695</td>
    </tr>
    <tr>
      <th>2</th>
      <td>hedley_2016/Wav Files 1/1113_Cassin's_Vireo_1_...</td>
      <td>2</td>
      <td>1.439637</td>
      <td>1.843084</td>
      <td>0.8</td>
      <td>1973</td>
      <td>3.946225</td>
      <td>-3.297062</td>
      <td>-0.347933</td>
      <td>0.368604</td>
      <td>...</td>
      <td>-13.315022</td>
      <td>-14.799085</td>
      <td>1</td>
      <td>1500.000000</td>
      <td>3724.592170</td>
      <td>6776.916971</td>
      <td>6.25</td>
      <td>-37.763107</td>
      <td>1.167537</td>
      <td>149.182406</td>
    </tr>
    <tr>
      <th>3</th>
      <td>hedley_2016/Wav Files 1/1113_Cassin's_Vireo_1_...</td>
      <td>3</td>
      <td>3.604898</td>
      <td>4.028662</td>
      <td>0.8</td>
      <td>1974</td>
      <td>3.209291</td>
      <td>-1.472756</td>
      <td>0.012070</td>
      <td>-0.722493</td>
      <td>...</td>
      <td>-13.210196</td>
      <td>-14.569655</td>
      <td>2</td>
      <td>1500.000000</td>
      <td>3798.581942</td>
      <td>6524.135804</td>
      <td>6.25</td>
      <td>-34.966949</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>hedley_2016/Wav Files 1/1113_Cassin's_Vireo_1_...</td>
      <td>4</td>
      <td>4.040272</td>
      <td>4.159274</td>
      <td>0.8</td>
      <td>1975</td>
      <td>0.337892</td>
      <td>2.038742</td>
      <td>1.111712</td>
      <td>0.800808</td>
      <td>...</td>
      <td>10.202535</td>
      <td>2.893551</td>
      <td>2</td>
      <td>4575.301882</td>
      <td>4725.160134</td>
      <td>4936.733992</td>
      <td>6.25</td>
      <td>-10.372253</td>
      <td>1.059631</td>
      <td>43.464143</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2687</th>
      <td>hedley_2016/Wav Files 3/1841_Cassin's_Vireo_1_...</td>
      <td>0</td>
      <td>0.000000</td>
      <td>0.121905</td>
      <td>0.8</td>
      <td>778</td>
      <td>-0.982202</td>
      <td>3.746105</td>
      <td>1.258669</td>
      <td>0.656011</td>
      <td>...</td>
      <td>9.680232</td>
      <td>2.545646</td>
      <td>1689</td>
      <td>4082.121425</td>
      <td>4608.508021</td>
      <td>5326.771592</td>
      <td>6.25</td>
      <td>-12.080605</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2688</th>
      <td>hedley_2016/Wav Files 3/1841_Cassin's_Vireo_1_...</td>
      <td>1</td>
      <td>1.233560</td>
      <td>1.613787</td>
      <td>0.8</td>
      <td>779</td>
      <td>0.207171</td>
      <td>-1.890158</td>
      <td>0.973335</td>
      <td>5.958722</td>
      <td>...</td>
      <td>-1.043776</td>
      <td>-3.734445</td>
      <td>1690</td>
      <td>1500.000000</td>
      <td>3639.036725</td>
      <td>7312.345246</td>
      <td>6.25</td>
      <td>-46.577782</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2689</th>
      <td>hedley_2016/Wav Files 3/1841_Cassin's_Vireo_1_...</td>
      <td>2</td>
      <td>1.950476</td>
      <td>2.089796</td>
      <td>0.8</td>
      <td>780</td>
      <td>1.633583</td>
      <td>2.349890</td>
      <td>0.771327</td>
      <td>1.764572</td>
      <td>...</td>
      <td>10.795265</td>
      <td>2.308394</td>
      <td>1690</td>
      <td>4460.767812</td>
      <td>4973.235868</td>
      <td>5394.703807</td>
      <td>6.25</td>
      <td>-17.789322</td>
      <td>1.130541</td>
      <td>100.897193</td>
    </tr>
    <tr>
      <th>2690</th>
      <td>hedley_2016/Wav Files 3/1841_Cassin's_Vireo_1_...</td>
      <td>3</td>
      <td>2.385850</td>
      <td>2.528073</td>
      <td>0.8</td>
      <td>781</td>
      <td>-0.562219</td>
      <td>0.969748</td>
      <td>-0.693975</td>
      <td>2.147093</td>
      <td>...</td>
      <td>6.591626</td>
      <td>-2.115031</td>
      <td>1690</td>
      <td>1791.207173</td>
      <td>2374.763711</td>
      <td>3128.292871</td>
      <td>6.25</td>
      <td>-26.665470</td>
      <td>0.849881</td>
      <td>201.754410</td>
    </tr>
    <tr>
      <th>2691</th>
      <td>hedley_2016/Wav Files 3/1841_Cassin's_Vireo_1_...</td>
      <td>4</td>
      <td>3.111474</td>
      <td>3.538141</td>
      <td>0.8</td>
      <td>782</td>
      <td>-1.515847</td>
      <td>-2.088365</td>
      <td>1.086043</td>
      <td>-0.465359</td>
      <td>...</td>
      <td>-0.342227</td>
      <td>-11.511266</td>
      <td>1690</td>
      <td>1519.137359</td>
      <td>3519.481183</td>
      <td>6360.844448</td>
      <td>6.25</td>
      <td>-39.351994</td>
      <td>0.847840</td>
      <td>74.121701</td>
    </tr>
  </tbody>
</table>
<p>2692 rows × 48 columns</p>
</div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># save the final data frame with all of these measures to a CSV file</span>
<span class="n">output</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">output_csv_path</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="preparation.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Preparation</p>
      </div>
    </a>
    <a class="right-next"
       href="humpback_whale.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Humpback whales</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Setup">Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Preprocessing">Preprocessing</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Segmentation">Segmentation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Run-model">Run model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Postprocessing">Postprocessing</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Mason Youngblood
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025, Mason Youngblood.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>